{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Algorithmic Bias \n",
    "\n",
    "---\n",
    "\n",
    "## Author:Â \n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Eoghan Hogan\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Eoghan.Hogan@ucdconnect.ie\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 17335293\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index:\n",
    "    \n",
    "- i - Imports\n",
    "- ii - Constants\n",
    "- iii - Data\n",
    "---\n",
    "- Question 1\n",
    "    - 1 - Exploring Data\n",
    "    - 2 - Data Classes\n",
    "    - 3 - Classifiers\n",
    "        - 3.1 - KNN (w/bias discussion)\n",
    "        - 3.2 - D-Trees (w/bias discussion)\n",
    "        - 3.3 - Log Regression (w/bias discussion)\n",
    "        - 3.4 - Gradient Boost (w/bias discussion)\n",
    "    - 4 - Scaling Data\n",
    "    - 5 - Exploring Scaled Data\n",
    "    - 6 - Scaled Classifiers\n",
    "        - 6.1 - KNN (w/bias discussion)\n",
    "        - 6.2 - D-Trees (w/bias discussion)\n",
    "        - 6.3 - Log Regression (w/bias discussion)\n",
    "        - 6.4 - Gradient Boost (w/bias discussion)\n",
    "    - 7 - Scaled Results vs Non-Scaled Results\n",
    "        - Non-Scaled Results\n",
    "        - Scaled Results\n",
    "        - All Results\n",
    "- Question 2\n",
    "    - 8 - Rectifying Sample Bias Strategy\n",
    "    - 9 - SMOTE\n",
    "    - 10 - Condensed Nearest Neighbour\n",
    "- Question 3\n",
    "    - 11 - Strategy Testing (New Dataset)\n",
    "    - 12 - Comparison of all methods\n",
    "- Conclusion\n",
    "---\n",
    "- References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "\n",
    "import imblearn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii - Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_n = 10\n",
    "kf = KFold(n_splits=cv_n, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii - Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "surv = pd.read_csv('survival.csv')\n",
    "surv['Survived'] = 'GE5'\n",
    "surv.loc[surv['Class']==2,'Survived']='L5'\n",
    "surv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Bias?\n",
    "\n",
    "Bias is when a data set is heavily Unbalanced in that one class dominates another by a certain factor. Biased Dataset can be 10:1 or 10000:1 if there are not alot of features even a small imbalance can bias towards the majoiry class. \n",
    "\n",
    "Bias can be a real problem as alot of really Interesting datasets have biased data.\n",
    "\n",
    "\n",
    "Bias in a Classifaction model is when a Classification model is Biased toward the Class that appears most inside the Sample Training data. That is the model predicts the Majoirty class most of the time becuase during training it will achieve a higher score by predicting the majority calss most of the time. Also during training getting the majority class wrong will not have a big impact on the training algorithm due to the amount of times sees a minority class sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Question 1\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary stats I cannot Identify anything \"odd\" the data is all clearly on different scales but for the time being I am leaving it. I will come back to scaling the data Later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age vs Class plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv[[\"Age\", \"Class\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year vs Class plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv[[\"Year\", \"Class\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNodes vs Class plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv[[\"NNodes\", \"Class\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "The plots as they stand did not provide any useful insight but it is always good practice to atleast try and explore the data in a bit of depth before doing anything else so although nothing major was revealed it was still worth the effort "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data Classes\n",
    "\n",
    "Here we look at the amount of Bias in the samples.\n",
    "we also pull out the lables and classes into their own arrays. \n",
    "We also take the features out into their own array to use for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = surv[\"Class\"].values\n",
    "labels = surv['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_y = Counter(labels)\n",
    "X = surv[[\"Age\", \"Year\", \"NNodes\"]].values\n",
    "\n",
    "print(f\"Shape of features: {X.shape}\")\n",
    "print(f\"Shape of output: {y.shape}\")\n",
    "print(f\"Classes:\\n\\tGE5(survived):\\t{c_y['GE5']}\\n\\tL5: {c_y['L5']}\")\n",
    "print(f\"Minority class : {round((c_y['L5']/len(y)), 3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up data for hold out\n",
    "\n",
    "For hold out we want to split the rraining and test data as we have done below. \n",
    "I also just wanted to check the Class bias in the Training and Testing Samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_ydist = round((Counter(y)[2]/len(y)) * 100, 2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "c1_tr = round(Counter(y_train)[1]/(len(y_train)) * 100, 4)\n",
    "c2_tr = round(Counter(y_train)[2]/(len(y_train)) *100, 4)\n",
    "c1_te = round(Counter(y_test)[1]/(len(y_test))* 100, 4)\n",
    "c2_te = round(Counter(y_test)[2]/(len(y_test))* 100, 4)\n",
    "print(f\"Class 1 in the Training samples: {c1_tr}%\")\n",
    "print(f\"Class 2 in the Training samples: {c2_tr}%\")\n",
    "print(f\"Class 1 in the Testing samples: {c1_te}%\")\n",
    "print(f\"Class 2 in the Testing samples: {c2_te}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 - K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "ho_knn_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {ho_knn_predmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Cross Validation Folds: {cv_n}\")\n",
    "y_pred = cross_val_predict(kNN, X, y, cv=kf)\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Minority class 2 in y: {c2_ydist}%\")\n",
    "cv_knn_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {cv_knn_predmin}%\\n\")\n",
    "scores = cross_val_score(kNN, X, y, cv=kf)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(kNN, X, y, cv=kf, scoring='f1')\n",
    "print(\"f1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(kNN, X, y, cv=kf, scoring='precision')\n",
    "print(\"precision: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(kNN, X, y, cv=kf, scoring='recall')\n",
    "print(\"recall: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN RESULTS\n",
    "The KNN heavily underpredicted the Minority class which is not surprising given when it does its distance calculations there would not be many of the moinority class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 - Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtree = DecisionTreeClassifier(criterion='entropy', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = Dtree.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "ho_dtree_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {ho_dtree_predmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Cross Validation Folds: {cv_n}\")\n",
    "y_pred = cross_val_predict(Dtree, X, y, cv=kf)\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Minority class 2 in y: {c2_ydist}%\")\n",
    "cv_dtree_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {cv_dtree_predmin}%\\n\")\n",
    "scores = cross_val_score(Dtree, X, y, cv=kf)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(Dtree, X, y, cv=kf, scoring='f1')\n",
    "print(\"f1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(Dtree, X, y, cv=kf, scoring='precision')\n",
    "print(\"precision: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(Dtree, X, y, cv=kf, scoring='recall')\n",
    "print(\"recall: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree RESULTS\n",
    "The Decision Tree underpredicted the Minority class when we done hold out testing and then surprisingly it overpredicted the minority class and I have a theory that since we only have 3 features that the Tree was able to learn a good split on the 3 Features so the imbalance was not so much of a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(solver='lbfgs', random_state=42, max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lreg.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "ho_lreg_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {ho_lreg_predmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Cross Validation Folds: {cv_n}\")\n",
    "y_pred = cross_val_predict(lreg, X, y, cv=kf)\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Minority class 2 in y: {c2_ydist}%\")\n",
    "cv_lreg_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {cv_lreg_predmin}%\\n\")\n",
    "scores = cross_val_score(lreg, X, y, cv=kf)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(lreg, X, y, cv=kf, scoring='f1')\n",
    "print(\"f1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(lreg, X, y, cv=kf, scoring='precision')\n",
    "print(\"precision: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(lreg, X, y, cv=kf, scoring='recall')\n",
    "print(\"recall: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression RESULTS\n",
    "Linear Regression underestimates The Minority Class by a massive margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg.fit(X_train, y_train)\n",
    "y_pred = gbreg.predict(X_test).round()\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "ho_gbreg_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {ho_gbreg_predmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf =  KFold(n_splits=cv_n, random_state=42, shuffle=True)\n",
    "print(f\"Number of Cross Validation Folds: {cv_n}\")\n",
    "y_pred = cross_val_predict(gbreg, X, y, cv=kf)\n",
    "y_pred = np.array(list(map(lambda x: round(x), y_pred)))\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Minority class 2 in y: {c2_ydist}%\")\n",
    "cv_gbreg_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {cv_gbreg_predmin}%\\n\")\n",
    "scores = cross_val_score(gbreg, X, y, cv=kf)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression RESULTS\n",
    "Gradient Boosting Regression The Minority Class by a smaller margin than linear regression but its still further off than the other methods. Regression as a whole underestimates and this isn't surprising given that the formulas rely heavily on the y variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Scaling Data\n",
    "\n",
    "### As we saw at the start all our data is varying alot in magnitude\n",
    "\n",
    "While this is not always a problem some Classifiers will Bias themselves towards the feature with the largest magnitude and as such it can be good practice to normalize the features. Here I am discretizing the ages in 6 bins that represent age ranges between 30 and 90. I a normailising the year with a MinMax scaler to bound it between 1 and 2. Finally I use a standar Scaler to Normailes the NNodes feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_scal = surv.copy()\n",
    "a = surv_scal[\"Age\"]\n",
    "yr = surv_scal[\"Year\"]\n",
    "nn = surv_scal[\"NNodes\"]\n",
    "print(\"*\" * 10, \"Before Scaling\", \"*\" * 10)\n",
    "print(\"Age Range:\", min(a), max(a))\n",
    "print(\"Year Range:\", min(yr), max(yr))\n",
    "print(\"NNodes Range:\", min(nn), max(nn), \"\\n\")\n",
    "kb = KBinsDiscretizer(n_bins=6, encode='ordinal', strategy='uniform')\n",
    "ss = StandardScaler()\n",
    "mms = MinMaxScaler((1,2))\n",
    "surv_scal[\"Age\"] = kb.fit_transform(surv_scal[\"Age\"].values.reshape(-1, 1)).flatten()\n",
    "surv_scal[\"Year\"] = mms.fit_transform(yr.values.reshape(-1, 1)).flatten()\n",
    "surv_scal[\"NNodes\"] = ss.fit_transform(nn.values.reshape(-1, 1)).flatten()\n",
    "a = surv_scal[\"Age\"]\n",
    "yr = surv_scal[\"Year\"]\n",
    "nn = surv_scal[\"NNodes\"]\n",
    "print(\"*\" * 10, \"After Scaling\", \"*\" * 10)\n",
    "print(\"Age Range:\", min(a), max(a))\n",
    "print(\"Year Range:\", min(yr), max(yr))\n",
    "print(\"NNodes Range:\", min(nn), max(nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Exploring Scaled data\n",
    "\n",
    "In which we see if we can draw anything useful from the Scaled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_scal.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary statistics of the scaled data do not tell us much about the data again However we can clearly see that the Features are all much closer together in magnitude which should help in stopping classifiers bias one feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots (Scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if the scaled data lends itself to more insightful plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age vs Class (Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_scal[[\"Age\", \"Class\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides seeing that our ages were correctly binned we are not provided with any insights from this plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year vs Class (Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_scal[[\"Year\", \"Class\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is very messy and does not provide us with any sort of inference. Even if we use a scatter plot we don't see anything insightful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNodes vs Class (Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_scal.plot(\"NNodes\", \"Class\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is not much variance however the bigest NNodes does lie inside class 2\n",
    "\n",
    "### Plots - While not lending themseleves to any insight it is still good practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Scaled Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we created new hold-out sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale = surv_scal[[\"Age\", \"Year\", \"NNodes\"]].values\n",
    "s_c2_ydist = round((Counter(y)[2]/len(y)) * 100, 2) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 - K-NN (Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 - Hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "sho_knn_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {ho_knn_predmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Cross Validation Folds: {cv_n}\")\n",
    "y_pred = cross_val_predict(kNN, X_scale, y, cv=kf)\n",
    "print(classification_report(y, y_pred))\n",
    "print(classification_report(y, y_pred)) \n",
    "print(f\"Minority class 2 in y: {s_c2_ydist}%\")\n",
    "scv_knn_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2) \n",
    "scores = cross_val_score(kNN, X_scale, y, cv=kf)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(kNN, X_scale, y, cv=kf, scoring='f1')\n",
    "print(\"f1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(kNN, X_scale, y, cv=kf, scoring='precision')\n",
    "print(\"precision: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(kNN, X_scale, y, cv=kf, scoring='recall')\n",
    "print(\"recall: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 - Decision Trees (Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtree = DecisionTreeClassifier(criterion='entropy', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Dtree.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "sho_dtree_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {ho_dtree_predmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Cross Validation Folds: {cv_n}\")\n",
    "y_pred = cross_val_predict(Dtree, X_scale, y, cv=kf)\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Minority class 2 in y: {s_c2_ydist}%\")\n",
    "scv_dtree_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {cv_dtree_predmin}%\\n\")\n",
    "scores = cross_val_score(Dtree, X_scale, y, cv=kf)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(Dtree, X_scale, y, cv=kf, scoring='f1')\n",
    "print(\"f1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(Dtree, X_scale, y, cv=kf, scoring='precision')\n",
    "print(\"precision: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(Dtree, X_scale, y, cv=kf, scoring='recall')\n",
    "print(\"recall: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 - Logistic Regression (Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(solver='lbfgs', random_state=42, max_iter=10000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 - Hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lreg.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "sho_lreg_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {ho_lreg_predmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Cross Validation Folds: {cv_n}\")\n",
    "y_pred = cross_val_predict(lreg, X_scale, y, cv=kf)\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Minority class 2 in y: {s_c2_ydist}%\")\n",
    "scv_lreg_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {cv_lreg_predmin}%\\n\")\n",
    "scores = cross_val_score(lreg, X_scale, y, cv=kf)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(lreg, X_scale, y, cv=kf, scoring='f1')\n",
    "print(\"f1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(lreg, X_scale, y, cv=kf, scoring='precision')\n",
    "print(\"precision: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(lreg, X_scale, y, cv=kf, scoring='recall')\n",
    "print(\"recall: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 - Gradient Boosting (Scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 - Hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg.fit(X_train, y_train)\n",
    "y_pred = gbreg.predict(X_test)\n",
    "y_pred = np.array(list(map(lambda x: round(x), y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "sho_gbreg_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {ho_gbreg_predmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Cross Validation Folds: {cv_n}\")\n",
    "y_pred = cross_val_predict(gbreg, X, y, cv=kf)\n",
    "y_pred = np.array(list(map(lambda x: round(x), y_pred)))\n",
    "print(classification_report(y, y_pred))\n",
    "print(f\"Minority class 2 in y: {s_c2_ydist}%\")\n",
    "scv_gbreg_predmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {cv_gbreg_predmin}%\\n\")\n",
    "scores = cross_val_score(gbreg, X, y, cv=kf)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Q1 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Non-Scaled Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [c2_ydist] * 4\n",
    "data2 = [ho_knn_predmin, ho_dtree_predmin, ho_lreg_predmin, ho_gbreg_predmin]\n",
    "data3 = [cv_knn_predmin, cv_dtree_predmin, cv_lreg_predmin, cv_gbreg_predmin]\n",
    "labels = [\"k-NN\", \"Decision Tree\", \"Linear Regression\", \"Gradient Boost\"]\n",
    "width =0.3\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(np.arange(len(data1)), data1, width=width)\n",
    "plt.bar(np.arange(len(data2))+ width, data2, width=width)\n",
    "plt.bar(np.arange(len(data3))+ width + width, data3, width=width)\n",
    "plt.xticks(range(len(data1)), labels)\n",
    "plt.xlabel('ML methood')\n",
    "plt.ylabel('percentage class 2 predicted')\n",
    "plt.title('Non-Scaled data - Classifier Bias')\n",
    "plt.legend([\"C2 in test\", \"c2 predicted for Hold Out\", \"C2 predicted for Cross Validation\" ],loc=\"best\",fontsize=\"x-large\")\n",
    "nsrplt = plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Scaled Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1  = [s_c2_ydist] * 4\n",
    "data2  = [sho_knn_predmin, sho_dtree_predmin, sho_lreg_predmin, sho_gbreg_predmin]\n",
    "data3  = [scv_knn_predmin, scv_dtree_predmin, scv_lreg_predmin, scv_gbreg_predmin]\n",
    "labels = [\"k-NN\", \"Decision Tree\", \"Linear Regression\", \"Gradient Boost\"]\n",
    "width  = 0.3\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(np.arange(len(data1)), data1, width=width)\n",
    "plt.bar(np.arange(len(data2))+ width, data2, width=width)\n",
    "plt.bar(np.arange(len(data3))+ width + width, data3, width=width)\n",
    "plt.xticks(range(len(data1)), labels)\n",
    "plt.xlabel('ML methood')\n",
    "plt.ylabel('percentage class 2 predicted')\n",
    "plt.title('Scaled data - Classifier Bias')\n",
    "plt.legend([\"C2 in test\", \"c2 predicted for Hold Out\", \"C2 predicted for Cross Validation\" ],loc=\"best\",fontsize=\"x-large\")\n",
    "srplt = plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [c2_ydist] * 4\n",
    "data2 = [ho_knn_predmin, ho_dtree_predmin, ho_lreg_predmin, ho_gbreg_predmin]\n",
    "data3 = [cv_knn_predmin, cv_dtree_predmin, cv_lreg_predmin, cv_gbreg_predmin]\n",
    "data4 = [sho_knn_predmin, sho_dtree_predmin, sho_lreg_predmin, sho_gbreg_predmin]\n",
    "data5 = [scv_knn_predmin, scv_dtree_predmin, scv_lreg_predmin, scv_gbreg_predmin]\n",
    "labels = [\"k-NN\", \"Decision Tree\", \"Linear Regression\", \"Gradient Boost\"]\n",
    "width = 0.15\n",
    "plt.figure(figsize=(15,10))\n",
    "l = np.arange(len(data1))\n",
    "plt.bar(l, data2, width=width)\n",
    "plt.bar(l + (width), data3, width=width)\n",
    "plt.bar(l + (width * 2), data1, width=width)\n",
    "plt.bar(l + (width * 3), data4, width=width)\n",
    "plt.bar(l + (width * 4), data5, width=width)\n",
    "plt.xticks(range(len(data1)), labels)\n",
    "plt.xlabel('ML methood')\n",
    "plt.ylabel('percentage class 2 predicted')\n",
    "plt.title('Scaled data - Classifier Bias')\n",
    "labels = [\"C2 predicted for Hold Out\", \"C2 predicted for Cross Validation\",\"C2 in test\"\n",
    " ,\"C2 predicted for Hold Out (scaled)\", \"C2 predicted for Cross Validation (scaled)\"]\n",
    "plt.legend(labels,loc=\"best\",fontsize=\"x-large\")\n",
    "nsandsplt = plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the reults together show us that scaling the data does not actually change the general pattern. infact in most cases we get ther same results withing a few percent. Nonetheless what we can conclude is that the KNN does the best at classifying correctly while being trained on a imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Question 2\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8\n",
    "\n",
    "For Question 2 I am going to Suggest Two Strategies Firstly we will Test _SMOTE_ and then _Condensed Nearest Neighbour Undersampling_. I choose CNN Undersampling because they made the most sense to me. \n",
    "\n",
    "Before we can continue I want to talk about Hyper-Parameter Tuning and why I did not approach the problem using parameter Tuning.\n",
    "\n",
    "While we have already seen Hyperparameters in this notebook and technially have already decided on some such as the values we plug into out k-folds and our random seeds. \n",
    "\n",
    "On reflection we could have gone a step further and then done a basic bayse search for hyperparams But if we are acknowledging that the Training samples are inherently Biased no amount of model parameter tuning is going to alliviate the Bias and thats why Methods of fixing Dataset Bias Exists and that is what we go onto explore with SMOTE and CNN undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 - Smote\n",
    "\n",
    "When we have imbalanced Data we will come up with the simplest approach to rectify it and that probably  involves duplicating examples in the minority class, although these examples donât add any new information to the model. Instead, new examples can be synthesized from the existing examples. This is a type of data augmentation for the minority class and is referred to as the Synthetic Minority Oversampling Technique -> SMOTE\n",
    "\n",
    "An improvement on duplicating examples from the minority class is to synthesize new examples from the minority class. This is a type of data augmentation for tabular data and can be very effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = pd.read_csv('survival.csv')\n",
    "surv['Survived'] = 'GE5'\n",
    "surv.loc[surv['Class']==2,'Survived']='L5'\n",
    "labels = surv[\"Survived\"]\n",
    "y = surv[\"Class\"]\n",
    "X = surv[[\"Age\", \"Year\", \"NNodes\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look again at the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_y = Counter(labels)\n",
    "classimba = [(i, (c_y[i] / sum(c_y.values())) ) for i in c_y]\n",
    "for i in classimba:\n",
    "    print(f\"{i[0]} - {c_y[i[0]]} samples - {round(i[1] * 100, 2)}% of total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Labels are split about 3/4 to 1/4 with GE5 containing most of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.8)\n",
    "X, y = over.fit_resample(X, y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y)\n",
    "classimba = [(i, (counter[i] / sum(counter.values())) ) for i in counter]\n",
    "for i in classimba:\n",
    "    print(f\"{i[0]} - {counter[i[0]]} samples - {round(i[1] * 100, 2)}% of total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "c = Counter(y_test)\n",
    "c2_te = round(c[2] / sum(c.values()) * 100, 2)\n",
    "print(\"{}% of test set is class 2\".format(c2_te))\n",
    "\n",
    "c = Counter(y_train)\n",
    "c2_tr = round(c[2] / sum(c.values()) * 100, 2)\n",
    "print(\"{}% of train set is class 2\".format(c2_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "knnpredmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {knnpredmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "y_pred = Dtree.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "dtreepredmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {knnpredmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(solver='lbfgs', random_state=42, max_iter=10000).fit(X_train, y_train)\n",
    "y_pred = lreg.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "lregpredmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {knnpredmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg = GradientBoostingRegressor(random_state=42)\n",
    "gbreg.fit(X_train, y_train)\n",
    "y_pred = gbreg.predict(X_test)\n",
    "y_pred = np.array(list(map(lambda x: round(x), y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "gbregpredmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {knnpredmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [testmin] * 4\n",
    "data2 = [knnpredmin, dtreepredmin, lregpredmin, gbregpredmin]\n",
    "labels = [\"k-NN\", \"D-Tree\", \"Lin. Reg.\", \"Grad. Boost\"]\n",
    "width =0.3\n",
    "plt.bar(np.arange(len(data1)), data1, width=width)\n",
    "plt.bar(np.arange(len(data2))+ width, data2, width=width)\n",
    "plt.xticks(range(len(data1)), labels)\n",
    "plt.xlabel('ML methood')\n",
    "plt.ylabel('percentage class 2 predicted')\n",
    "plt.title('SMOTE: Test class 2 (blue) vs Predicted Class 2(Orange)')\n",
    "smoteresplt = plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how SMOTE has effected our Results in comparison to before. Now the only one that still suffers from the imbalance is Linear Regression the rest of the methods do well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 - Condensed Nearest Neighbour Undersampling\n",
    "\n",
    "Condensed Nearest Neighbors, or CNN for short, is an undersampling technique that seeks a subset of a collection of samples that results in no loss in model performance, referred to as a minimal consistent set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the Dataset. Splitting off Classes and Class Labels. Summarising what happened after Application of Condensed nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = pd.read_csv('survival.csv')\n",
    "surv['Survived'] = 'GE5'\n",
    "surv.loc[surv['Class']==2,'Survived']='L5'\n",
    "labels = surv[\"Survived\"]\n",
    "y = surv[\"Class\"]\n",
    "X = surv[[\"Age\", \"Year\", \"NNodes\"]].values\n",
    "undersample = CondensedNearestNeighbour(n_neighbors=1)\n",
    "X, y = undersample.fit_resample(X, y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y)\n",
    "classimba = [(i, (counter[i] / sum(counter.values())) ) for i in counter]\n",
    "for i in classimba:\n",
    "    print(f\"{i[0]} - {counter[i[0]]} samples - {round(i[1] * 100, 2)}% of total\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "c = Counter(y_test)\n",
    "c2_te = round(c[2] / sum(c.values()) * 100, 2)\n",
    "print(\"percent of class 2 in test set {}\".format(c2_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that when We applied CNN that the samples became equal in in length the Condensed nearest Neighbour algoirthm was able to maintain the same variance in our samples but reducede what we needed down to 81 samples in each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "knnpredmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {knnpredmin}%\")\n",
    "rocauc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"roc auc score: {rocauc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dtree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "y_pred = Dtree.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "dtreepredmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {dtreepredmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression(solver='lbfgs', random_state=42, max_iter=10000).fit(X_train, y_train)\n",
    "y_pred = lreg.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "lregpredmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {lregpredmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbreg = GradientBoostingRegressor(random_state=42)\n",
    "gbreg.fit(X_train, y_train)\n",
    "y_pred = gbreg.predict(X_test)\n",
    "y_pred = np.array(list(map(lambda x: round(x), y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "testmin = c2_te\n",
    "print(f\"Minority class in test set: {testmin}%\")\n",
    "gbregpredmin = round((Counter(y_pred)[2]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {gbregpredmin}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cnn Results on BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [testmin] * 4\n",
    "data2 = [knnpredmin, dtreepredmin, lregpredmin, gbregpredmin]\n",
    "labels = [\"k-NN\", \"D-Tree\", \"Lin. Reg.\", \"Grad. Boost\"]\n",
    "width =0.3\n",
    "plt.bar(np.arange(len(data1)), data1, width=width)\n",
    "plt.bar(np.arange(len(data2))+ width, data2, width=width)\n",
    "plt.xticks(range(len(data1)), labels)\n",
    "plt.xlabel('ML methood')\n",
    "plt.ylabel('percentage class 2 predicted')\n",
    "plt.title('Condensed Nearest Neighbours \\n Test class 2 (blue) vs Predicted Class 2(Orange)')\n",
    "cnnresplt = plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Using Condensed Nearest Neighbour Undersampling that the Bias for class predictions changes comapred to no rectifying strategy. the k-NN actually is now biased towards picking Class 2. this is very interesting. The Undersampling brought the number of samples down to  82 and 81 respectivley and then we train test split at 50% meaning we are only using 40 samples really to test. This could be an explanation for these results. the classes are now as balanced as they can be but also (and this is a very important point) due to the small testing sample we cannot draw anything conclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Question 3\n",
    "---\n",
    "---\n",
    "## 11 - New Dataset\n",
    "We are going to use The Diabetes Data set which is imbalanced and see how the Methods Compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = './diabetes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(dataset)\n",
    "print(\"Original Class Balance\")\n",
    "y = raw_df.pop(\"Outcome\")\n",
    "X = raw_df.values\n",
    "counter = Counter(y)\n",
    "classimba = [(i, (counter[i] / sum(counter.values())) ) for i in counter]\n",
    "for i in classimba:\n",
    "    print(f\"{i[0]} - {counter[i[0]]} samples - {round(i[1] * 100, 2)}% of total\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "c = Counter(y_train)\n",
    "trminc = round(c[1] / sum(c.values()) * 100, 4)\n",
    "print(\"train minority: \", trminc)\n",
    "c = Counter(y_test)\n",
    "teminc = round(c[1] / sum(c.values()) * 100, 4)\n",
    "print(\"test minority: \", teminc)\n",
    "print(\"X_train, X_test, y_train, y_test\", len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SMOTE Class Balance\")\n",
    "raw_df = pd.read_csv(dataset)\n",
    "y = raw_df.pop(\"Outcome\")\n",
    "X = raw_df.values\n",
    "over = SMOTE(sampling_strategy=0.8, random_state=42)\n",
    "X, y = over.fit_resample(X, y)\n",
    "counter = Counter(y)\n",
    "classimba = [(i, (counter[i] / sum(counter.values())) ) for i in counter]\n",
    "for i in classimba:\n",
    "    print(f\"{i[0]} - {counter[i[0]]} samples - {round(i[1] * 100, 2)}% of total\")\n",
    "OX_train, OX_test, Oy_train, Oy_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "c = Counter(Oy_train)\n",
    "trOminc = round(c[1] / sum(c.values()) * 100, 4)\n",
    "print(\"train minority: \", trOminc)\n",
    "c = Counter(Oy_test)\n",
    "teOminc = round(c[1] / sum(c.values()) * 100, 4)\n",
    "print(\"test minority: \", teOminc)\n",
    "print(\"OX_train {}, OX_test {}, Oy_train {}, Oy_test{}\".format(len(OX_train), len(OX_test), len(Oy_train), len(Oy_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Condensed NN Undersample Class Balance\")\n",
    "raw_df = pd.read_csv(dataset)\n",
    "y = raw_df.pop(\"Outcome\")\n",
    "X = raw_df.values\n",
    "undersample = CondensedNearestNeighbour(n_neighbors=1, random_state=42)\n",
    "X, y = undersample.fit_resample(X, y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y)\n",
    "classimba = [(i, (counter[i] / sum(counter.values())) ) for i in counter]\n",
    "for i in classimba:\n",
    "    print(f\"{i[0]} - {counter[i[0]]} samples - {round(i[1] * 100, 2)}% of total\")\n",
    "CX_train, CX_test, Cy_train, Cy_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "c = Counter(Cy_train)\n",
    "trCminc = round(c[1] / sum(c.values()) * 100, 4)\n",
    "print(\"train minority: \", trCminc)\n",
    "c = Counter(Cy_test)\n",
    "teCminc = round(c[1] / sum(c.values()) * 100, 4)\n",
    "print(f\"test minority: {teCminc}\")\n",
    "print(\"CX_train {}, CX_test {}, Cy_train {}, Cy_test {}\".format(len(CX_train), len(CX_test), len(Cy_train), len(Cy_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 K Neares Neighbours (k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data\")\n",
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Minority class in test set: {teminc}%\")\n",
    "knnpred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {knnpred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")\n",
    "print(\"\\nSMOTE\")\n",
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = kNN.fit(OX_train, Oy_train).predict(OX_test)\n",
    "print(classification_report(Oy_test, y_pred))\n",
    "print(f\"Minority class in test set: {teOminc}%\")\n",
    "oknnpred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {oknnpred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(Oy_test, y_pred)}\")\n",
    "print(\"\\nCNN\")\n",
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = kNN.fit(CX_train, Cy_train).predict(CX_test)\n",
    "print(classification_report(Cy_test, y_pred))\n",
    "print(f\"Minority class in test set: {teCminc}%\")\n",
    "cknnpred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {cknnpred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(Cy_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data\")\n",
    "Dtree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "y_pred = Dtree.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Minority class in test set: {teminc}%\")\n",
    "dtreepred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {dtreepred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")\n",
    "print(\"\\nSMOTE\")\n",
    "Dtree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "y_pred = Dtree.fit(OX_train, Oy_train).predict(OX_test)\n",
    "print(classification_report(Oy_test, y_pred))\n",
    "print(f\"Minority class in test set: {teOminc}%\")\n",
    "odtreepred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {odtreepred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(Oy_test, y_pred)}\")\n",
    "print(\"\\nCNN\")\n",
    "Dtree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "y_pred = Dtree.fit(CX_train, Cy_train).predict(CX_test)\n",
    "print(classification_report(Cy_test, y_pred))\n",
    "print(f\"Minority class in test set: {teCminc}%\")\n",
    "cdtreepred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {cdtreepred }%\")\n",
    "print(f\"roc auc score: {roc_auc_score(Cy_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data\")\n",
    "lreg = LogisticRegression(solver='lbfgs', random_state=42, max_iter=10000).fit(X_train, y_train)\n",
    "y_pred = lreg.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Minority class in test set: {teminc}%\")\n",
    "lregpred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {lregpred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "print(\"\\nSMOTE\")\n",
    "lreg = LogisticRegression(solver='lbfgs', random_state=42, max_iter=10000).fit(OX_train, Oy_train)\n",
    "y_pred = lreg.fit(OX_train, Oy_train).predict(OX_test)\n",
    "print(classification_report(Oy_test, y_pred))\n",
    "print(f\"Minority class in test set: {teOminc}%\")\n",
    "olregpred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : { olregpred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(Oy_test, y_pred)}\")\n",
    "\n",
    "print(\"\\nCNN\")\n",
    "lreg = LogisticRegression(solver='lbfgs', random_state=42, max_iter=10000).fit(CX_train, Cy_train)\n",
    "y_pred = lreg.fit(CX_train, Cy_train).predict(CX_test)\n",
    "print(classification_report(Cy_test, y_pred))\n",
    "print(f\"Minority class in test set: {teCminc}%\")\n",
    "\n",
    "clregpred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : {clregpred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(Cy_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data\")\n",
    "gbreg = GradientBoostingRegressor(random_state=42)\n",
    "gbreg.fit(X_train, y_train)\n",
    "y_pred = gbreg.predict(X_test)\n",
    "y_pred = np.array(list(map(lambda x: round(x), y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Minority class in test set: {teminc}%\")\n",
    "gbregpred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2)\n",
    "print(f\"Predicted minority class : { gbregpred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "print(\"\\nSMOTE\")\n",
    "gbreg = GradientBoostingRegressor(random_state=42)\n",
    "gbreg.fit(OX_train, Oy_train)\n",
    "y_pred = gbreg.predict(OX_test)\n",
    "y_pred = np.array(list(map(lambda x: round(x), y_pred)))\n",
    "print(classification_report(Oy_test, y_pred))\n",
    "print(f\"Minority class in test set: {teOminc}%\")\n",
    "ogbregpred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {ogbregpred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(Oy_test, y_pred)}\")\n",
    "\n",
    "print(\"\\nCNN\")\n",
    "gbreg = GradientBoostingRegressor(random_state=42)\n",
    "gbreg.fit(CX_train, Cy_train)\n",
    "y_pred = gbreg.predict(CX_test)\n",
    "y_pred = np.array(list(map(lambda x: round(x), y_pred)))\n",
    "print(classification_report(Cy_test, y_pred))\n",
    "print(f\"Minority class in test set: {teCminc}%\")\n",
    "cgbregpred = round((Counter(y_pred)[1]/len(y_pred)) * 100, 2) \n",
    "print(f\"Predicted minority class : {cgbregpred}%\")\n",
    "print(f\"roc auc score: {roc_auc_score(Cy_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "data1 = [teminc] * 4\n",
    "data2 = [teOminc] * 4\n",
    "data3 = [teCminc] * 4\n",
    "data1 = data1+data2+data3\n",
    "data2 = [knnpred, dtreepred, lregpred, gbregpred,\n",
    "        oknnpred, odtreepred, olregpred, ogbregpred,\n",
    "        cknnpred, cdtreepred, clregpred, cgbregpred]\n",
    "labels1 = [\"k-NN\", \"D-Tree\", \"Lin. Reg.\", \"Grad. Boost\"]\n",
    "labels2 = [\"SMOTE k-NN\", \"SMOTE D-Tree\", \"SMOTE Lin. Reg.\", \"SMOTE Grad. Boost\"]\n",
    "labels3 = [\"CNN k-NN\", \"CNN D-Tree\", \"CNN Lin. Reg.\", \"CNN Grad. Boost\"]\n",
    "labels = labels1+labels2+labels3\n",
    "width = 0.15\n",
    "plt.figure(figsize=(20,15))\n",
    "l = np.arange(len(data1))\n",
    "predbars = plt.bar(l + (width * 1.5), data2, width=width)\n",
    "testbars = plt.bar(l, data1, width=(width*2))\n",
    "plt.xticks(l, labels, rotation=20)\n",
    "plt.xlabel('ML methood')\n",
    "plt.ylabel('percentage class 2')\n",
    "plt.title('Scaled data - Classifier Bias')\n",
    "\n",
    "for i in range(len(testbars)):\n",
    "    if i < 4:\n",
    "        testbars[i].set_color('#ed3528')\n",
    "        predbars[i].set_color('#4245f4')\n",
    "    if i >=4 and i < 8:\n",
    "        testbars[i].set_color('#c2dd27')\n",
    "        predbars[i].set_color('#1fcce2')\n",
    "    if i >=8 and i < 12:\n",
    "        testbars[i].set_color('#20e21d')\n",
    "        predbars[i].set_color('#a13aea')\n",
    "        \n",
    "legend_elements = [\n",
    "                    Line2D([0], [0], color='#ed3528', lw=6, label='Original Test Minority Class'),\n",
    "                    Line2D([0], [0], color='#4245f4', lw=6, label='Original Preicted Minority Class'),\n",
    "                    Line2D([0], [0], color='#c2dd27', lw=6, label='SMOTE Test Minority Class'),\n",
    "                    Line2D([0], [0], color='#1fcce2', lw=6, label='Smote Preicted Minority Class'),\n",
    "                    Line2D([0], [0], color='#20e21d', lw=6, label='CNN Test Minority Class'),\n",
    "                    Line2D([0], [0], color='#a13aea', lw=6, label='CNN Preicted Minority Class')\n",
    "]\n",
    "plt.legend(handles=legend_elements,loc=\"best\",fontsize=\"x-large\")\n",
    "x = plt.figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have a bar-chart showing us all the comparisons of using nothing to rectify the Bias, using Smote and then using Condensed Nearest Neighbour Undersampling.\n",
    "\n",
    "When we used SMOTE we can see that our predictions are overall much closer to the true number of thre minority class in the test set. Also an Interesting note is that the smote predictions seem to follow the same pattern as the no sampling except closer to the actual predictions but knn is stil more than all, dtree and gradient boost are roughly the same and the Linear regression still predicts the minority the least. \n",
    "\n",
    "The Condensed Nearest Neighbour undersampling on the data produces some very Interesting results. The KNN and D-Tree classifiers to very well and the bias is seemingly removed however Linear Regression and Gradient Boost infact are biased towards the original minority class. I suppose The reason that the Linear Regression and Gradient Boost are biased towards the original minority class is because once we apply CNN Undersampling the Minority Class becomes the Majoirty by 7%.\n",
    "\n",
    "While in the previous Dataset we saw that CNN undersampling gave us great results here we see that it actually ends up being inferior to smote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Conclusion_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haves seen throughout this notebook what Bias is and how we can attempt to remove it. We see that using Over Sampling and Undersampling Strategies can remove Bias from our Samples and thus remove it from our Models. \n",
    "\n",
    "Something else Interesting we can draw from our experiements here is that the Regression Models are much more sensitive to Bias We can see this as they often underclassify the minority class much more than a k-NN and a Decision Tree. we also see that the best model out of the 4 for dealing with bias with theses small feature datasets. \n",
    "\n",
    "Overall we can clearly conclude that Bias in a sample set leads to Machine Learning Models being Biased. which in itself is a great conclusion to be able to draw as it arms us with the knowledge goign forward how Bias effects Models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpass1",
   "language": "python",
   "name": "mlpass1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
